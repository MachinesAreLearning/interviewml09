{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) - Traditional NLP\n",
    "## Interview Preparation Notebook for Senior Applied AI Scientist (Retail Banking)\n",
    "\n",
    "---\n",
    "\n",
    "**Goal**: Demonstrate mastery of sequence labeling for entity extraction, with emphasis on banking-specific entities and production deployment considerations.\n",
    "\n",
    "**Interview Signal**: This notebook shows you can extract structured information from unstructured text - critical for automation and compliance in banking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Context (Banking Lens)\n",
    "\n",
    "### Why NER Exists in Retail Banking\n",
    "\n",
    "Banks process millions of documents containing critical information that needs to be extracted and structured. NER transforms unstructured text into actionable data.\n",
    "\n",
    "| Use Case | Entities to Extract | Business Impact |\n",
    "|----------|--------------------|-----------------|\n",
    "| **KYC Document Processing** | Names, addresses, dates of birth, ID numbers | Automate customer onboarding |\n",
    "| **Transaction Monitoring** | Names, amounts, dates, locations | Detect suspicious patterns |\n",
    "| **Complaint Analysis** | Product names, branch locations, employee names | Route and track issues |\n",
    "| **Contract Analysis** | Party names, dates, monetary amounts, terms | Risk assessment |\n",
    "| **PII Detection** | SSN, account numbers, phone numbers | Compliance and data protection |\n",
    "\n",
    "### The Business Problem\n",
    "\n",
    "> \"We receive 10,000 wire transfer requests per day in free-text format. How do we extract the sender, recipient, amount, and purpose automatically?\"\n",
    "\n",
    "**Without NER**: Manual data entry, 10 minutes per request, error-prone  \n",
    "**With NER**: Automatic extraction, <1 second, consistent quality\n",
    "\n",
    "### Real Banking Example\n",
    "\n",
    "**Input**: \"Please transfer $5,000 from my checking account to John Smith at Bank of America, routing number 026009593, for rent payment by December 15, 2024.\"\n",
    "\n",
    "**NER Output**:\n",
    "```\n",
    "- MONEY: $5,000\n",
    "- ACCOUNT_TYPE: checking account\n",
    "- PERSON: John Smith\n",
    "- ORG: Bank of America\n",
    "- ROUTING_NUM: 026009593\n",
    "- PURPOSE: rent payment\n",
    "- DATE: December 15, 2024\n",
    "```\n",
    "\n",
    "### Interview Framing\n",
    "\n",
    "```\n",
    "\"NER in banking is different from general NER because we have domain-specific entities \n",
    "like account numbers, routing numbers, and transaction codes that standard models don't \n",
    "recognize. We also have strict requirements around PII detection - missing a Social \n",
    "Security Number in an email before it goes to an external party is a compliance violation. \n",
    "So I focus on high recall for sensitive entities, even if precision suffers slightly.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problem Definition\n",
    "\n",
    "### Task Type: Sequence Labeling\n",
    "\n",
    "| Aspect | Description |\n",
    "|--------|-------------|\n",
    "| **Learning Type** | Supervised (requires labeled sequences) |\n",
    "| **Input** | Sequence of tokens (words) |\n",
    "| **Output** | Sequence of labels (one per token) |\n",
    "| **Core Challenge** | Label dependencies (\"New\" followed by \"York\" = LOCATION) |\n",
    "\n",
    "### Labeling Schemes\n",
    "\n",
    "**BIO (Begin-Inside-Outside)**:\n",
    "```\n",
    "John     Smith    lives    in    New      York    City\n",
    "B-PER    I-PER    O        O     B-LOC    I-LOC   I-LOC\n",
    "```\n",
    "\n",
    "**BILOU (Begin-Inside-Last-Outside-Unit)**:\n",
    "```\n",
    "John     Smith    lives    in    New      York    City\n",
    "B-PER    L-PER    O        O     B-LOC    I-LOC   L-LOC\n",
    "```\n",
    "\n",
    "### Why Traditional Approaches Before LLMs\n",
    "\n",
    "1. **CRFs capture label dependencies**: P(y_t | y_{t-1}, x) - previous label affects current\n",
    "2. **Feature engineering gives domain control**: Can add gazetteer features for banking terms\n",
    "3. **Interpretable**: Can inspect feature weights to understand model behavior\n",
    "4. **Fast inference**: Critical for real-time processing\n",
    "5. **Works with limited data**: Effective with 5,000-10,000 labeled sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset\n",
    "\n",
    "### Public Dataset: CoNLL-2003\n",
    "\n",
    "We use CoNLL-2003, the standard benchmark for NER, as a proxy for banking entity recognition.\n",
    "\n",
    "**Standard entity types**:\n",
    "- PER (Person)\n",
    "- ORG (Organization)\n",
    "- LOC (Location)\n",
    "- MISC (Miscellaneous)\n",
    "\n",
    "**Banking-relevant mapping**:\n",
    "- PER → Customer names, counterparty names\n",
    "- ORG → Bank names, company names\n",
    "- LOC → Branch locations, addresses\n",
    "- MISC → Product names, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install scikit-learn nltk spacy seqeval pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NER-specific imports\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample NER data (CoNLL format simulation)\n",
    "# In production, you'd load from datasets library or local files\n",
    "\n",
    "# Sample sentences with BIO tags\n",
    "sample_data = [\n",
    "    # Banking-style sentences\n",
    "    [\n",
    "        (\"Please\", \"O\"), (\"transfer\", \"O\"), (\"$\", \"B-MONEY\"), (\"5,000\", \"I-MONEY\"),\n",
    "        (\"to\", \"O\"), (\"John\", \"B-PER\"), (\"Smith\", \"I-PER\"), (\"at\", \"O\"),\n",
    "        (\"Bank\", \"B-ORG\"), (\"of\", \"I-ORG\"), (\"America\", \"I-ORG\"), (\".\", \"O\")\n",
    "    ],\n",
    "    [\n",
    "        (\"The\", \"O\"), (\"account\", \"O\"), (\"holder\", \"O\"), (\"Mary\", \"B-PER\"),\n",
    "        (\"Johnson\", \"I-PER\"), (\"called\", \"O\"), (\"from\", \"O\"), (\"New\", \"B-LOC\"),\n",
    "        (\"York\", \"I-LOC\"), (\"branch\", \"O\"), (\".\", \"O\")\n",
    "    ],\n",
    "    [\n",
    "        (\"Wire\", \"O\"), (\"transfer\", \"O\"), (\"of\", \"O\"), (\"$\", \"B-MONEY\"),\n",
    "        (\"10,000\", \"I-MONEY\"), (\"to\", \"O\"), (\"ABC\", \"B-ORG\"), (\"Corporation\", \"I-ORG\"),\n",
    "        (\"on\", \"O\"), (\"December\", \"B-DATE\"), (\"15\", \"I-DATE\"), (\".\", \"O\")\n",
    "    ],\n",
    "    [\n",
    "        (\"Customer\", \"O\"), (\"Robert\", \"B-PER\"), (\"Lee\", \"I-PER\"), (\"reported\", \"O\"),\n",
    "        (\"fraud\", \"O\"), (\"at\", \"O\"), (\"Chase\", \"B-ORG\"), (\"ATM\", \"O\"),\n",
    "        (\"in\", \"O\"), (\"Chicago\", \"B-LOC\"), (\".\", \"O\")\n",
    "    ],\n",
    "    [\n",
    "        (\"Please\", \"O\"), (\"contact\", \"O\"), (\"Sarah\", \"B-PER\"), (\"Williams\", \"I-PER\"),\n",
    "        (\"at\", \"O\"), (\"JPMorgan\", \"B-ORG\"), (\"for\", \"O\"), (\"assistance\", \"O\"), (\".\", \"O\")\n",
    "    ],\n",
    "]\n",
    "\n",
    "# Generate more synthetic data\n",
    "names = [(\"Michael\", \"Brown\"), (\"Jennifer\", \"Davis\"), (\"David\", \"Wilson\"), \n",
    "         (\"Lisa\", \"Anderson\"), (\"James\", \"Taylor\"), (\"Emily\", \"Thomas\")]\n",
    "orgs = [\"Wells Fargo\", \"Citibank\", \"Goldman Sachs\", \"Morgan Stanley\", \"Capital One\"]\n",
    "locations = [\"Los Angeles\", \"San Francisco\", \"Boston\", \"Miami\", \"Seattle\", \"Denver\"]\n",
    "amounts = [\"$1,000\", \"$2,500\", \"$50,000\", \"$100\", \"$25,000\"]\n",
    "\n",
    "# Generate additional sentences\n",
    "for _ in range(50):\n",
    "    name = names[np.random.randint(len(names))]\n",
    "    org = orgs[np.random.randint(len(orgs))].split()\n",
    "    loc = locations[np.random.randint(len(locations))].split()\n",
    "    amount = amounts[np.random.randint(len(amounts))]\n",
    "    \n",
    "    # Template 1: Transfer request\n",
    "    sentence = [\n",
    "        (\"Transfer\", \"O\"), (amount.split()[0], \"B-MONEY\"),\n",
    "    ]\n",
    "    if len(amount.split()) > 1:\n",
    "        sentence.append((amount.split()[1], \"I-MONEY\"))\n",
    "    \n",
    "    sentence.extend([\n",
    "        (\"to\", \"O\"), (name[0], \"B-PER\"), (name[1], \"I-PER\"),\n",
    "        (\"at\", \"O\")\n",
    "    ])\n",
    "    \n",
    "    for i, org_word in enumerate(org):\n",
    "        sentence.append((org_word, \"B-ORG\" if i == 0 else \"I-ORG\"))\n",
    "    \n",
    "    sentence.append((\".\", \"O\"))\n",
    "    sample_data.append(sentence)\n",
    "\n",
    "print(f\"Generated {len(sample_data)} sentences for NER training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the data\n",
    "all_tags = []\n",
    "all_words = []\n",
    "\n",
    "for sentence in sample_data:\n",
    "    for word, tag in sentence:\n",
    "        all_words.append(word)\n",
    "        all_tags.append(tag)\n",
    "\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "print(\"TAG DISTRIBUTION\")\n",
    "print(\"=\" * 40)\n",
    "for tag, count in sorted(tag_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {tag}: {count} ({100*count/len(all_tags):.1f}%)\")\n",
    "\n",
    "# Entity type distribution (combining B- and I-)\n",
    "entity_types = defaultdict(int)\n",
    "for tag in all_tags:\n",
    "    if tag != \"O\":\n",
    "        entity_type = tag.split(\"-\")[1]\n",
    "        entity_types[entity_type] += 1\n",
    "\n",
    "print(f\"\\nENTITY TYPE DISTRIBUTION\")\n",
    "print(\"=\" * 40)\n",
    "for etype, count in sorted(entity_types.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {etype}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample sentences\n",
    "print(\"SAMPLE ANNOTATED SENTENCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, sentence in enumerate(sample_data[:3]):\n",
    "    print(f\"\\nSentence {i+1}:\")\n",
    "    tokens = [word for word, _ in sentence]\n",
    "    tags = [tag for _, tag in sentence]\n",
    "    \n",
    "    # Print aligned\n",
    "    print(\" \".join(tokens))\n",
    "    \n",
    "    # Highlight entities\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    current_words = []\n",
    "    \n",
    "    for word, tag in sentence:\n",
    "        if tag.startswith(\"B-\"):\n",
    "            if current_entity:\n",
    "                entities.append((\" \".join(current_words), current_entity))\n",
    "            current_entity = tag[2:]\n",
    "            current_words = [word]\n",
    "        elif tag.startswith(\"I-\") and current_entity:\n",
    "            current_words.append(word)\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append((\" \".join(current_words), current_entity))\n",
    "                current_entity = None\n",
    "                current_words = []\n",
    "    \n",
    "    if current_entity:\n",
    "        entities.append((\" \".join(current_words), current_entity))\n",
    "    \n",
    "    print(f\"Entities: {entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Traditional NLP Pipeline\n",
    "\n",
    "### 4.1 Feature Engineering for NER\n",
    "\n",
    "Traditional NER relies heavily on hand-crafted features. This is where domain expertise matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Feature extractor for traditional NER.\n",
    "    \n",
    "    Features capture:\n",
    "    1. Word-level features (shape, case, prefixes/suffixes)\n",
    "    2. Context features (surrounding words)\n",
    "    3. Gazetteer features (known entity lists)\n",
    "    4. Banking-specific patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Banking-specific gazetteers\n",
    "        self.bank_names = {'chase', 'wells', 'fargo', 'citibank', 'jpmorgan', \n",
    "                          'goldman', 'sachs', 'morgan', 'stanley', 'capital'}\n",
    "        self.money_words = {'$', 'dollar', 'dollars', 'usd', 'amount', 'balance'}\n",
    "        self.date_words = {'january', 'february', 'march', 'april', 'may', 'june',\n",
    "                          'july', 'august', 'september', 'october', 'november', 'december'}\n",
    "        \n",
    "    def word_shape(self, word):\n",
    "        \"\"\"Convert word to shape pattern (e.g., 'John' -> 'Xxxx').\"\"\"\n",
    "        shape = []\n",
    "        for char in word:\n",
    "            if char.isupper():\n",
    "                shape.append('X')\n",
    "            elif char.islower():\n",
    "                shape.append('x')\n",
    "            elif char.isdigit():\n",
    "                shape.append('d')\n",
    "            else:\n",
    "                shape.append(char)\n",
    "        return ''.join(shape)\n",
    "    \n",
    "    def short_shape(self, word):\n",
    "        \"\"\"Compressed shape (consecutive same types merged).\"\"\"\n",
    "        shape = self.word_shape(word)\n",
    "        short = [shape[0]]\n",
    "        for char in shape[1:]:\n",
    "            if char != short[-1]:\n",
    "                short.append(char)\n",
    "        return ''.join(short)\n",
    "    \n",
    "    def extract_features(self, sentence, position):\n",
    "        \"\"\"\n",
    "        Extract features for a token at given position.\n",
    "        \n",
    "        Features include:\n",
    "        - Current word features\n",
    "        - Context window features (prev/next words)\n",
    "        - Gazetteer features\n",
    "        - Position features\n",
    "        \"\"\"\n",
    "        word = sentence[position][0]\n",
    "        features = {}\n",
    "        \n",
    "        # === Current word features ===\n",
    "        features['word.lower'] = word.lower()\n",
    "        features['word.isupper'] = word.isupper()\n",
    "        features['word.istitle'] = word.istitle()\n",
    "        features['word.isdigit'] = word.isdigit()\n",
    "        features['word.shape'] = self.word_shape(word)\n",
    "        features['word.short_shape'] = self.short_shape(word)\n",
    "        \n",
    "        # Prefix and suffix (important for names)\n",
    "        features['word.prefix2'] = word[:2].lower()\n",
    "        features['word.prefix3'] = word[:3].lower()\n",
    "        features['word.suffix2'] = word[-2:].lower()\n",
    "        features['word.suffix3'] = word[-3:].lower()\n",
    "        \n",
    "        # Length features\n",
    "        features['word.len'] = len(word)\n",
    "        features['word.len>5'] = len(word) > 5\n",
    "        \n",
    "        # === Banking-specific features ===\n",
    "        features['word.is_bank'] = word.lower() in self.bank_names\n",
    "        features['word.is_money'] = word.lower() in self.money_words or word == '$'\n",
    "        features['word.is_date'] = word.lower() in self.date_words\n",
    "        features['word.has_digit'] = any(c.isdigit() for c in word)\n",
    "        features['word.is_currency_symbol'] = word in '$£€'\n",
    "        features['word.looks_like_amount'] = bool(re.match(r'^[\\d,]+\\.?\\d*$', word))\n",
    "        \n",
    "        # === Position features ===\n",
    "        features['BOS'] = position == 0  # Beginning of sentence\n",
    "        features['EOS'] = position == len(sentence) - 1  # End of sentence\n",
    "        features['position'] = position\n",
    "        \n",
    "        # === Context features (previous word) ===\n",
    "        if position > 0:\n",
    "            prev_word = sentence[position - 1][0]\n",
    "            features['prev.word.lower'] = prev_word.lower()\n",
    "            features['prev.word.istitle'] = prev_word.istitle()\n",
    "            features['prev.word.isupper'] = prev_word.isupper()\n",
    "            features['prev.word.is_prep'] = prev_word.lower() in {'at', 'to', 'from', 'in', 'of'}\n",
    "        else:\n",
    "            features['prev.BOS'] = True\n",
    "        \n",
    "        # === Context features (next word) ===\n",
    "        if position < len(sentence) - 1:\n",
    "            next_word = sentence[position + 1][0]\n",
    "            features['next.word.lower'] = next_word.lower()\n",
    "            features['next.word.istitle'] = next_word.istitle()\n",
    "            features['next.word.isupper'] = next_word.isupper()\n",
    "        else:\n",
    "            features['next.EOS'] = True\n",
    "        \n",
    "        # === Bigram features ===\n",
    "        if position > 0:\n",
    "            features['bigram.prev'] = f\"{sentence[position-1][0].lower()}_{word.lower()}\"\n",
    "        if position < len(sentence) - 1:\n",
    "            features['bigram.next'] = f\"{word.lower()}_{sentence[position+1][0].lower()}\"\n",
    "        \n",
    "        return features\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = NERFeatureExtractor()\n",
    "\n",
    "# Demonstrate features\n",
    "print(\"FEATURE EXTRACTION EXAMPLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "example_sentence = sample_data[0]\n",
    "for i, (word, tag) in enumerate(example_sentence[:6]):\n",
    "    features = feature_extractor.extract_features(example_sentence, i)\n",
    "    print(f\"\\n{word} ({tag}):\")\n",
    "    # Show key features\n",
    "    key_features = ['word.lower', 'word.istitle', 'word.shape', 'word.is_bank', 'word.is_money']\n",
    "    for f in key_features:\n",
    "        if f in features:\n",
    "            print(f\"  {f}: {features[f]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Why CRF Over Simple Classifiers?\n",
    "\n",
    "**Problem with independent classification**:\n",
    "- Classifying each token independently ignores label dependencies\n",
    "- \"New\" could be B-LOC (New York) or O (new account)\n",
    "- Context from previous label helps: if previous is B-LOC, current is likely I-LOC\n",
    "\n",
    "**CRF (Conditional Random Field)** models:\n",
    "$$P(\\mathbf{y}|\\mathbf{x}) = \\frac{1}{Z(\\mathbf{x})} \\exp\\left(\\sum_t \\sum_k \\lambda_k f_k(y_{t-1}, y_t, \\mathbf{x}, t)\\right)$$\n",
    "\n",
    "Where:\n",
    "- $f_k$ are feature functions that can depend on current label, previous label, and input\n",
    "- $\\lambda_k$ are learned weights\n",
    "- $Z(\\mathbf{x})$ is the normalization constant\n",
    "\n",
    "**For this demo**, we'll use a simpler approach (token-level classification) that still demonstrates the concepts, but production systems should use CRFs or BiLSTM-CRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "def prepare_data(sentences, feature_extractor):\n",
    "    \"\"\"Convert sentences to feature dictionaries and labels.\"\"\"\n",
    "    X = []  # Feature dictionaries\n",
    "    y = []  # Labels\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            features = feature_extractor.extract_features(sentence, i)\n",
    "            label = sentence[i][1]\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Prepare training data\n",
    "X_features, y_labels = prepare_data(sample_data, feature_extractor)\n",
    "\n",
    "print(f\"Total tokens: {len(X_features)}\")\n",
    "print(f\"Unique labels: {set(y_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (keeping sentence structure for proper evaluation)\n",
    "train_sents, test_sents = train_test_split(sample_data, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train, y_train = prepare_data(train_sents, feature_extractor)\n",
    "X_test, y_test = prepare_data(test_sents, feature_extractor)\n",
    "\n",
    "print(f\"Training tokens: {len(X_train)}\")\n",
    "print(f\"Test tokens: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize features\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_train_vec.shape}\")\n",
    "print(f\"Number of features: {len(vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train token-level classifier\n",
    "# In production, use CRF (sklearn-crfsuite) or BiLSTM-CRF\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE,\n",
    "    class_weight='balanced',  # Handle imbalance (O is majority)\n",
    "    C=1.0\n",
    ")\n",
    "\n",
    "print(\"Training NER model...\")\n",
    "model.fit(X_train_vec, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Token-level accuracy\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(f\"\\nToken-level accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nTOKEN-LEVEL CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER Inference function\n",
    "class NERPredictor:\n",
    "    \"\"\"\n",
    "    Production NER predictor.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, vectorizer, feature_extractor):\n",
    "        self.model = model\n",
    "        self.vectorizer = vectorizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Simple tokenization (production would use spacy).\"\"\"\n",
    "        # Handle punctuation\n",
    "        text = re.sub(r'([.,!?])', r' \\1', text)\n",
    "        return text.split()\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Predict entities in text.\n",
    "        \n",
    "        Returns:\n",
    "            List of (entity_text, entity_type, start_pos, end_pos) tuples\n",
    "        \"\"\"\n",
    "        tokens = self.tokenize(text)\n",
    "        \n",
    "        # Create dummy sentence format for feature extraction\n",
    "        sentence = [(token, \"O\") for token in tokens]\n",
    "        \n",
    "        # Extract features for each token\n",
    "        features = []\n",
    "        for i in range(len(sentence)):\n",
    "            feat = self.feature_extractor.extract_features(sentence, i)\n",
    "            features.append(feat)\n",
    "        \n",
    "        # Vectorize and predict\n",
    "        X = self.vectorizer.transform(features)\n",
    "        predictions = self.model.predict(X)\n",
    "        \n",
    "        # Extract entities from BIO tags\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        current_tokens = []\n",
    "        start_idx = 0\n",
    "        \n",
    "        for i, (token, tag) in enumerate(zip(tokens, predictions)):\n",
    "            if tag.startswith(\"B-\"):\n",
    "                # Save previous entity if exists\n",
    "                if current_entity:\n",
    "                    entities.append({\n",
    "                        'text': ' '.join(current_tokens),\n",
    "                        'type': current_entity,\n",
    "                        'start': start_idx,\n",
    "                        'end': i\n",
    "                    })\n",
    "                current_entity = tag[2:]\n",
    "                current_tokens = [token]\n",
    "                start_idx = i\n",
    "            elif tag.startswith(\"I-\") and current_entity:\n",
    "                current_tokens.append(token)\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append({\n",
    "                        'text': ' '.join(current_tokens),\n",
    "                        'type': current_entity,\n",
    "                        'start': start_idx,\n",
    "                        'end': i\n",
    "                    })\n",
    "                    current_entity = None\n",
    "                    current_tokens = []\n",
    "        \n",
    "        # Don't forget last entity\n",
    "        if current_entity:\n",
    "            entities.append({\n",
    "                'text': ' '.join(current_tokens),\n",
    "                'type': current_entity,\n",
    "                'start': start_idx,\n",
    "                'end': len(tokens)\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'tokens': tokens,\n",
    "            'tags': list(predictions),\n",
    "            'entities': entities\n",
    "        }\n",
    "\n",
    "# Initialize predictor\n",
    "ner_predictor = NERPredictor(model, vectorizer, feature_extractor)\n",
    "\n",
    "# Test inference\n",
    "test_texts = [\n",
    "    \"Please transfer $5,000 to John Smith at Chase Bank.\",\n",
    "    \"The customer Mary Johnson called from the New York branch.\",\n",
    "    \"Wire $25,000 to ABC Corporation by December 15.\"\n",
    "]\n",
    "\n",
    "print(\"NER INFERENCE EXAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text in test_texts:\n",
    "    result = ner_predictor.predict(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Entities found:\")\n",
    "    for entity in result['entities']:\n",
    "        print(f\"  - {entity['text']} ({entity['type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation Strategy\n",
    "\n",
    "### Why Token-Level Accuracy is NOT Enough\n",
    "\n",
    "**Problem**: Most tokens are \"O\" (outside any entity)\n",
    "- Model predicts \"O\" for everything → 80% accuracy\n",
    "- But extracts 0 entities → useless\n",
    "\n",
    "### Entity-Level Evaluation\n",
    "\n",
    "**Exact Match**: Entity is correct only if ALL tokens and the type match\n",
    "- Prediction: \"New York\" as LOC ✓\n",
    "- Prediction: \"New\" as LOC (missing \"York\") ✗\n",
    "- Prediction: \"New York\" as ORG (wrong type) ✗\n",
    "\n",
    "**Metrics**:\n",
    "- **Entity Precision**: % of predicted entities that are correct\n",
    "- **Entity Recall**: % of true entities that were found\n",
    "- **Entity F1**: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity-level evaluation\n",
    "def extract_entities_from_tags(tokens, tags):\n",
    "    \"\"\"Extract entities from BIO tags.\"\"\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    current_tokens = []\n",
    "    \n",
    "    for i, (token, tag) in enumerate(zip(tokens, tags)):\n",
    "        if tag.startswith(\"B-\"):\n",
    "            if current_entity:\n",
    "                entities.append((tuple(current_tokens), current_entity))\n",
    "            current_entity = tag[2:]\n",
    "            current_tokens = [token]\n",
    "        elif tag.startswith(\"I-\") and current_entity:\n",
    "            current_tokens.append(token)\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append((tuple(current_tokens), current_entity))\n",
    "                current_entity = None\n",
    "                current_tokens = []\n",
    "    \n",
    "    if current_entity:\n",
    "        entities.append((tuple(current_tokens), current_entity))\n",
    "    \n",
    "    return set(entities)\n",
    "\n",
    "def entity_level_metrics(true_sentences, pred_tags_all):\n",
    "    \"\"\"Calculate entity-level precision, recall, F1.\"\"\"\n",
    "    all_true_entities = set()\n",
    "    all_pred_entities = set()\n",
    "    \n",
    "    pred_idx = 0\n",
    "    for sentence in true_sentences:\n",
    "        tokens = [w for w, t in sentence]\n",
    "        true_tags = [t for w, t in sentence]\n",
    "        pred_tags = pred_tags_all[pred_idx:pred_idx + len(sentence)]\n",
    "        pred_idx += len(sentence)\n",
    "        \n",
    "        true_entities = extract_entities_from_tags(tokens, true_tags)\n",
    "        pred_entities = extract_entities_from_tags(tokens, pred_tags)\n",
    "        \n",
    "        all_true_entities.update(true_entities)\n",
    "        all_pred_entities.update(pred_entities)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    correct = all_true_entities & all_pred_entities\n",
    "    \n",
    "    precision = len(correct) / max(1, len(all_pred_entities))\n",
    "    recall = len(correct) / max(1, len(all_true_entities))\n",
    "    f1 = 2 * precision * recall / max(0.001, precision + recall)\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'correct': len(correct),\n",
    "        'predicted': len(all_pred_entities),\n",
    "        'actual': len(all_true_entities)\n",
    "    }\n",
    "\n",
    "# Calculate entity-level metrics\n",
    "metrics = entity_level_metrics(test_sents, y_pred)\n",
    "\n",
    "print(\"ENTITY-LEVEL EVALUATION\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "print(f\"\\nCorrect: {metrics['correct']} / {metrics['actual']} actual entities\")\n",
    "print(f\"Predicted: {metrics['predicted']} entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Production Readiness Checklist\n",
    "\n",
    "```\n",
    "DATA & PREPROCESSING\n",
    "[ ] Tokenization matches training (same tokenizer!)\n",
    "[ ] Handle special characters and unicode\n",
    "[ ] Max sequence length handling (split long documents)\n",
    "[ ] Language detection (model trained on English only?)\n",
    "\n",
    "MODEL ARTIFACTS\n",
    "[ ] Serialized model with version\n",
    "[ ] Feature extractor with gazetteers\n",
    "[ ] Vectorizer (vocabulary must match)\n",
    "[ ] Model card with training data description\n",
    "\n",
    "INFERENCE PIPELINE\n",
    "[ ] Batch processing for high volume\n",
    "[ ] Streaming for real-time extraction\n",
    "[ ] Confidence scores per entity\n",
    "[ ] Latency benchmarks (p50 < 50ms for short text)\n",
    "\n",
    "ENTITY-SPECIFIC CONCERNS\n",
    "[ ] PII entities flagged for special handling\n",
    "[ ] Entity validation (is extracted SSN valid format?)\n",
    "[ ] Entity linking to knowledge base\n",
    "[ ] Nested entity handling (if needed)\n",
    "\n",
    "BANKING-SPECIFIC\n",
    "[ ] Account number format validation\n",
    "[ ] Routing number validation (ABA check digit)\n",
    "[ ] Money amount normalization ($1,000 → 1000.00)\n",
    "[ ] Date normalization (Dec 15 → 2024-12-15)\n",
    "[ ] PII redaction before downstream processing\n",
    "\n",
    "MONITORING & DRIFT\n",
    "[ ] Entity distribution monitoring (sudden drop in PER?)\n",
    "[ ] Unknown word rate (vocabulary drift)\n",
    "[ ] Confidence score distribution\n",
    "[ ] Human annotation feedback loop\n",
    "\n",
    "GOVERNANCE\n",
    "[ ] Audit trail for extracted entities\n",
    "[ ] Explainability (why was this tagged?)\n",
    "[ ] Bias assessment (does model miss certain name patterns?)\n",
    "[ ] Regular revalidation with fresh annotations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production NER with validation\n",
    "import re\n",
    "\n",
    "class ProductionNER:\n",
    "    \"\"\"\n",
    "    Production-ready NER with banking-specific validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "        \n",
    "        # Validation patterns\n",
    "        self.ssn_pattern = re.compile(r'^\\d{3}-\\d{2}-\\d{4}$')\n",
    "        self.routing_pattern = re.compile(r'^\\d{9}$')\n",
    "        self.account_pattern = re.compile(r'^\\d{8,17}$')\n",
    "    \n",
    "    def validate_entity(self, entity_text, entity_type):\n",
    "        \"\"\"\n",
    "        Validate extracted entity.\n",
    "        Returns (is_valid, normalized_value, validation_notes)\n",
    "        \"\"\"\n",
    "        if entity_type == 'MONEY':\n",
    "            # Normalize money amount\n",
    "            cleaned = re.sub(r'[,$]', '', entity_text)\n",
    "            try:\n",
    "                amount = float(cleaned)\n",
    "                return True, amount, \"Valid amount\"\n",
    "            except ValueError:\n",
    "                return False, None, \"Could not parse amount\"\n",
    "        \n",
    "        elif entity_type == 'ROUTING_NUM':\n",
    "            digits = re.sub(r'\\D', '', entity_text)\n",
    "            if self.routing_pattern.match(digits):\n",
    "                # Could add ABA check digit validation here\n",
    "                return True, digits, \"Valid routing format\"\n",
    "            return False, None, \"Invalid routing number format\"\n",
    "        \n",
    "        elif entity_type == 'PER':\n",
    "            # Basic name validation\n",
    "            if len(entity_text.split()) >= 1:\n",
    "                return True, entity_text.title(), \"Name detected\"\n",
    "            return False, None, \"Name too short\"\n",
    "        \n",
    "        # Default: accept as-is\n",
    "        return True, entity_text, \"No validation applied\"\n",
    "    \n",
    "    def extract(self, text):\n",
    "        \"\"\"\n",
    "        Extract and validate entities.\n",
    "        \"\"\"\n",
    "        result = self.predictor.predict(text)\n",
    "        \n",
    "        validated_entities = []\n",
    "        for entity in result['entities']:\n",
    "            is_valid, normalized, notes = self.validate_entity(\n",
    "                entity['text'], entity['type']\n",
    "            )\n",
    "            \n",
    "            validated_entities.append({\n",
    "                'text': entity['text'],\n",
    "                'type': entity['type'],\n",
    "                'is_valid': is_valid,\n",
    "                'normalized': normalized,\n",
    "                'validation_notes': notes,\n",
    "                'is_pii': entity['type'] in ['PER', 'SSN', 'ACCOUNT_NUM']\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'original_text': text,\n",
    "            'entities': validated_entities,\n",
    "            'pii_detected': any(e['is_pii'] for e in validated_entities)\n",
    "        }\n",
    "\n",
    "# Test production NER\n",
    "prod_ner = ProductionNER(ner_predictor)\n",
    "\n",
    "test_text = \"Transfer $5,000 to John Smith at Chase Bank by December 15.\"\n",
    "result = prod_ner.extract(test_text)\n",
    "\n",
    "print(\"PRODUCTION NER OUTPUT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Input: {result['original_text']}\")\n",
    "print(f\"PII Detected: {result['pii_detected']}\")\n",
    "print(\"\\nEntities:\")\n",
    "for entity in result['entities']:\n",
    "    print(f\"  {entity['text']} ({entity['type']})\")\n",
    "    print(f\"    Valid: {entity['is_valid']}, Normalized: {entity['normalized']}\")\n",
    "    if entity['is_pii']:\n",
    "        print(f\"    ⚠️  PII - Handle with care\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modern LLM-Based Approach\n",
    "\n",
    "### How would we solve NER with LLMs today?\n",
    "\n",
    "**Option 1: Fine-tuned BERT-NER**\n",
    "```python\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(label_list)\n",
    ")\n",
    "# Fine-tune on banking NER data\n",
    "```\n",
    "\n",
    "**Option 2: Zero-shot NER with GPT**\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Extract entities from the following banking text:\n",
    "\n",
    "Text: \"Transfer $5,000 to John Smith at Chase Bank\"\n",
    "\n",
    "Extract these entity types:\n",
    "- PERSON: Names of people\n",
    "- ORGANIZATION: Bank or company names\n",
    "- MONEY: Dollar amounts\n",
    "- DATE: Dates mentioned\n",
    "\n",
    "Output as JSON:\n",
    "```\n",
    "\n",
    "**Option 3: GLiNER (Zero-shot NER)**\n",
    "```python\n",
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
    "entities = model.predict_entities(\n",
    "    text,\n",
    "    labels=[\"person\", \"organization\", \"money\", \"date\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode for LLM-based NER\n",
    "def create_ner_prompt(text, entity_types):\n",
    "    \"\"\"\n",
    "    Create prompt for LLM-based entity extraction.\n",
    "    \n",
    "    Banking production considerations:\n",
    "    - PII must be handled according to data policy\n",
    "    - Use structured output (JSON) for reliable parsing\n",
    "    - Include examples for consistency\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a banking document entity extractor.\n",
    "\n",
    "Extract the following entity types from the text:\n",
    "\"\"\"\n",
    "    \n",
    "    entity_descriptions = {\n",
    "        'PERSON': 'Names of individuals (customers, employees)',\n",
    "        'ORGANIZATION': 'Bank names, company names, institutions',\n",
    "        'MONEY': 'Dollar amounts, monetary values',\n",
    "        'DATE': 'Dates, deadlines, time references',\n",
    "        'ACCOUNT': 'Account numbers, routing numbers',\n",
    "        'LOCATION': 'Addresses, branch locations, cities'\n",
    "    }\n",
    "    \n",
    "    for etype in entity_types:\n",
    "        desc = entity_descriptions.get(etype, 'Entity')\n",
    "        prompt += f\"- {etype}: {desc}\\n\"\n",
    "    \n",
    "    prompt += f\"\"\"\n",
    "Text: \"{text}\"\n",
    "\n",
    "Output as JSON with format:\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\"text\": \"extracted text\", \"type\": \"ENTITY_TYPE\", \"start\": 0, \"end\": 10}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "JSON:\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Example prompt\n",
    "example_prompt = create_ner_prompt(\n",
    "    \"Transfer $5,000 to John Smith at Chase Bank by December 15.\",\n",
    "    ['PERSON', 'ORGANIZATION', 'MONEY', 'DATE']\n",
    ")\n",
    "\n",
    "print(\"EXAMPLE LLM NER PROMPT\")\n",
    "print(\"=\" * 50)\n",
    "print(example_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Traditional vs LLM Decision Matrix\n",
    "\n",
    "| Dimension | Traditional (CRF/BiLSTM-CRF) | LLM (Fine-tuned BERT) | LLM (Zero-shot GPT) |\n",
    "|-----------|---------------------------|----------------------|--------------------|\n",
    "| **Entity F1** | 85-90% | 92-95% | 75-85% |\n",
    "| **Latency** | <20ms | 50-200ms | 500ms-2s |\n",
    "| **Training data** | 5K-10K sentences | 1K-5K sentences | 0-100 examples |\n",
    "| **New entity types** | Requires retraining | Requires retraining | Just update prompt |\n",
    "| **Nested entities** | Difficult | Difficult | Natural |\n",
    "| **Explainability** | High (feature weights) | Low (attention only) | Medium (can ask why) |\n",
    "| **Cost per doc** | ~$0 | $0.0001-0.001 | $0.001-0.01 |\n",
    "| **Domain adaptation** | Requires labeled data | Requires labeled data | Few examples suffice |\n",
    "\n",
    "### When to Use Each Approach\n",
    "\n",
    "**Use Traditional (CRF)**:\n",
    "- High volume document processing (millions/day)\n",
    "- Stable entity types that don't change\n",
    "- Need explainability for compliance\n",
    "- Latency-critical applications\n",
    "\n",
    "**Use Fine-tuned BERT**:\n",
    "- Accuracy is paramount\n",
    "- Have GPU infrastructure\n",
    "- Sufficient labeled data available\n",
    "\n",
    "**Use Zero-shot LLM**:\n",
    "- New entity types needed quickly\n",
    "- No labeled data available\n",
    "- Complex nested entities\n",
    "- Low volume, high value documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interview Soundbites\n",
    "\n",
    "### Ready-to-Say Statements\n",
    "\n",
    "**On CRF vs Softmax:**\n",
    "> \"I use CRF over softmax for NER because label dependencies matter. The probability of 'I-PER' given 'B-PER' as previous tag is much higher than given 'B-LOC'. CRFs model this transition probability directly, leading to more coherent entity spans.\"\n",
    "\n",
    "**On Feature Engineering:**\n",
    "> \"Good NER is 70% feature engineering in traditional approaches. Word shape features ('Xxxx' for 'John') capture capitalization patterns without memorizing specific names. Gazetteer features give us known entity lists. Context features capture phrases like 'at [ORG]' or 'to [PERSON]'.\"\n",
    "\n",
    "**On Evaluation:**\n",
    "> \"Token-level accuracy is misleading for NER because most tokens are 'O'. A model predicting 'O' for everything gets 80% accuracy but extracts zero entities. I always use entity-level F1 with exact matching - the entire span and type must be correct.\"\n",
    "\n",
    "**On Banking-Specific NER:**\n",
    "> \"Standard NER models miss banking entities like routing numbers and account numbers. We train custom recognizers with format validation - a 9-digit routing number must also pass the ABA check digit algorithm to be valid.\"\n",
    "\n",
    "**On PII Detection:**\n",
    "> \"For PII detection in banking, I optimize for recall over precision. Missing a Social Security Number in an outbound email is a compliance violation. False positives just mean extra review - false negatives mean regulatory risk.\"\n",
    "\n",
    "**On Production Failures:**\n",
    "> \"NER models fail on entity boundaries - 'Bank of America' might be tagged as just 'Bank' or include surrounding words. This is why entity linking post-processing is critical - if 'Bank of' doesn't match any known bank, extend the span.\"\n",
    "\n",
    "**On When NOT to Use LLMs:**\n",
    "> \"For high-volume NER like processing wire transfers, I wouldn't use GPT-4. At $0.01 per document and 100K documents per day, that's $1M per year just for entity extraction. A fine-tuned model does the same job at 0.1% of the cost.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Common Interview Questions\n",
    "\n",
    "**Q: How do you handle nested entities?**\n",
    "> Nested entities (like \"Bank of America headquarters\" containing both ORG and LOC) are hard for BIO tagging. Options: (1) flatten to outermost entity, (2) use separate models per entity type, (3) use span-based models instead of sequence labeling, (4) LLMs handle this naturally.\n",
    "\n",
    "**Q: What's the BIO encoding and why?**\n",
    "> BIO = Begin, Inside, Outside. It distinguishes the start of an entity from its continuation, which is critical when two entities of the same type are adjacent. Without B/I distinction, \"John Smith Mary Johnson\" would be one long PERSON entity.\n",
    "\n",
    "**Q: How do you handle out-of-vocabulary words?**\n",
    "> Traditional models struggle with OOV. Mitigations: (1) character n-gram features that generalize, (2) word shape features that capture patterns, (3) subword tokenization (BPE), (4) pre-trained embeddings. Transformer models handle this better with subword tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║                    NOTEBOOK SUMMARY                               ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║  Task: Named Entity Recognition (NER)                            ║\n",
    "║  Approach: Traditional NLP (Feature Engineering + Classifier)    ║\n",
    "║  Banking Use: PII detection, document extraction                 ║\n",
    "║                                                                  ║\n",
    "║  Key Takeaways:                                                  ║\n",
    "║  1. CRF models label dependencies (B-PER → I-PER)                ║\n",
    "║  2. Feature engineering is critical (shape, gazetteer, context)  ║\n",
    "║  3. Entity-level F1, not token accuracy                          ║\n",
    "║  4. PII requires high recall, low tolerance for misses           ║\n",
    "║  5. Validation post-processing (routing number check digit)      ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
