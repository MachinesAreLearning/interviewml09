{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with LLMs - Modern Approaches\n",
    "## Interview Preparation Notebook for Senior Applied AI Scientist (Retail Banking)\n",
    "\n",
    "---\n",
    "\n",
    "**Goal**: Demonstrate mastery of transformer-based NER including BERT-NER, zero-shot entity extraction, and LLM-based approaches like GLiNER.\n",
    "\n",
    "**Interview Signal**: This notebook shows you can extract structured information from unstructured text using modern approaches while understanding accuracy/cost tradeoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Context (Banking Lens)\n",
    "\n",
    "### Why LLMs for NER Now?\n",
    "\n",
    "| Traditional NER Limitation | LLM Solution |\n",
    "|---------------------------|---------------|\n",
    "| Fixed entity types | Zero-shot extracts any entity type |\n",
    "| Struggles with context | Understands \"Apple\" as company vs fruit |\n",
    "| Domain adaptation costly | Few examples sufficient |\n",
    "| Nested entities hard | Naturally handles complex structures |\n",
    "\n",
    "### Banking Use Cases\n",
    "\n",
    "1. **Document Processing**: Extract parties, amounts, dates from contracts\n",
    "2. **PII Detection**: Find SSNs, account numbers, names in any document\n",
    "3. **Transaction Parsing**: Extract structured data from free-text descriptions\n",
    "4. **Compliance**: Identify regulated entities in communications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problem Definition\n",
    "\n",
    "### LLM NER Approaches\n",
    "\n",
    "| Approach | Training | Entity Types | Accuracy | Speed |\n",
    "|----------|----------|--------------|----------|-------|\n",
    "| **Fine-tuned BERT-NER** | Required | Fixed at training | 92-95% F1 | 50-100ms |\n",
    "| **spaCy Transformers** | Optional | Customizable | 88-93% F1 | 30-80ms |\n",
    "| **GLiNER (Zero-shot)** | None | Any | 80-88% F1 | 100-200ms |\n",
    "| **LLM Prompting** | None | Any | 75-90% F1 | 500ms-2s |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install transformers torch spacy pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sample banking texts for NER\n",
    "sample_texts = [\n",
    "    \"Please transfer $5,000 from my checking account to John Smith at Bank of America by December 15, 2024.\",\n",
    "    \"The customer Mary Johnson (SSN: 123-45-6789) called from the New York branch regarding account #987654321.\",\n",
    "    \"Wire transfer of $25,000 to ABC Corporation, routing number 021000089, for invoice INV-2024-001.\",\n",
    "    \"Contact Sarah Williams at JPMorgan Chase for questions about the mortgage application submitted on November 1st.\"\n",
    "]\n",
    "\n",
    "print(f\"Sample texts: {len(sample_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. Implementation\n",
    "\n",
    "### 4.1 BERT-NER (Fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT-NER pseudocode\n",
    "'''\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# Load fine-tuned NER model\n",
    "model_name = \"dslim/bert-base-NER\"  # Pre-trained on CoNLL-2003\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Create pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Extract entities\n",
    "text = \"Transfer $5,000 to John Smith at Bank of America\"\n",
    "entities = ner_pipeline(text)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['word']}: {entity['entity_group']} ({entity['score']:.2%})\")\n",
    "'''\n",
    "\n",
    "print(\"BERT-NER pseudocode shown above.\")\n",
    "print(\"Standard entity types: PER, ORG, LOC, MISC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 GLiNER (Zero-shot NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLiNER pseudocode - zero-shot NER\n",
    "'''\n",
    "from gliner import GLiNER\n",
    "\n",
    "# Load model\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
    "\n",
    "# Define custom entity types for banking\n",
    "labels = [\"person\", \"organization\", \"money\", \"date\", \"account_number\", \"routing_number\"]\n",
    "\n",
    "# Extract entities\n",
    "text = \"Transfer $5,000 to John Smith at Bank of America by December 15\"\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']}: {entity['label']} ({entity['score']:.2%})\")\n",
    "'''\n",
    "\n",
    "print(\"GLiNER zero-shot NER pseudocode shown above.\")\n",
    "print(\"Key advantage: Define ANY entity types without training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 LLM-Based NER (GPT/Claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ner_prompt(text, entity_types):\n",
    "    \"\"\"Create prompt for LLM-based entity extraction.\"\"\"\n",
    "    \n",
    "    entity_descriptions = {\n",
    "        \"PERSON\": \"Names of individuals\",\n",
    "        \"ORGANIZATION\": \"Company, bank, or institution names\",\n",
    "        \"MONEY\": \"Monetary amounts with currency\",\n",
    "        \"DATE\": \"Dates and time references\",\n",
    "        \"ACCOUNT_NUMBER\": \"Bank account numbers\",\n",
    "        \"ROUTING_NUMBER\": \"Bank routing/ABA numbers\",\n",
    "        \"SSN\": \"Social Security Numbers (format: XXX-XX-XXXX)\",\n",
    "        \"PHONE\": \"Phone numbers\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"Extract entities from the following banking text.\n",
    "\n",
    "Entity types to extract:\n",
    "\"\"\"\n",
    "    for etype in entity_types:\n",
    "        desc = entity_descriptions.get(etype, etype)\n",
    "        prompt += f\"- {etype}: {desc}\\n\"\n",
    "    \n",
    "    prompt += f\"\"\"\n",
    "Text: \"{text}\"\n",
    "\n",
    "Output as JSON:\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\"text\": \"extracted text\", \"type\": \"ENTITY_TYPE\", \"start\": 0, \"end\": 10}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Extract ALL entities of the specified types. Be precise with character positions.\n",
    "\n",
    "JSON:\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Example\n",
    "text = sample_texts[1]\n",
    "prompt = create_ner_prompt(text, [\"PERSON\", \"SSN\", \"ORGANIZATION\", \"ACCOUNT_NUMBER\"])\n",
    "\n",
    "print(\"LLM NER PROMPT\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated LLM NER response\n",
    "def simulate_llm_ner(text):\n",
    "    \"\"\"Simulate LLM NER with regex patterns for banking entities.\"\"\"\n",
    "    entities = []\n",
    "    \n",
    "    # Money pattern\n",
    "    for match in re.finditer(r'\\$[\\d,]+(?:\\.\\d{2})?', text):\n",
    "        entities.append({\"text\": match.group(), \"type\": \"MONEY\", \"start\": match.start(), \"end\": match.end()})\n",
    "    \n",
    "    # SSN pattern\n",
    "    for match in re.finditer(r'\\d{3}-\\d{2}-\\d{4}', text):\n",
    "        entities.append({\"text\": match.group(), \"type\": \"SSN\", \"start\": match.start(), \"end\": match.end()})\n",
    "    \n",
    "    # Account number pattern\n",
    "    for match in re.finditer(r'#(\\d{6,12})', text):\n",
    "        entities.append({\"text\": match.group(1), \"type\": \"ACCOUNT_NUMBER\", \"start\": match.start()+1, \"end\": match.end()})\n",
    "    \n",
    "    # Routing number pattern\n",
    "    for match in re.finditer(r'routing number (\\d{9})', text.lower()):\n",
    "        entities.append({\"text\": match.group(1), \"type\": \"ROUTING_NUMBER\", \"start\": match.start(), \"end\": match.end()})\n",
    "    \n",
    "    # Date patterns\n",
    "    for match in re.finditer(r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2}(?:st|nd|rd|th)?,?\\s*\\d{4}?', text):\n",
    "        entities.append({\"text\": match.group(), \"type\": \"DATE\", \"start\": match.start(), \"end\": match.end()})\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Test\n",
    "print(\"SIMULATED LLM NER RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "for text in sample_texts:\n",
    "    entities = simulate_llm_ner(text)\n",
    "    print(f\"\\nText: {text[:60]}...\")\n",
    "    for e in entities:\n",
    "        print(f\"  {e['text']}: {e['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-6. Evaluation\n",
    "\n",
    "### Entity-Level F1 (Same as Traditional)\n",
    "- Exact match: text span AND type must match\n",
    "- Partial match: overlapping spans counted separately\n",
    "\n",
    "### LLM-Specific Considerations\n",
    "- **Hallucination**: LLM might \"find\" entities that don't exist\n",
    "- **Format compliance**: Did LLM return valid JSON?\n",
    "- **Position accuracy**: Are start/end positions correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Production Readiness Checklist\n",
    "\n",
    "```\n",
    "OUTPUT VALIDATION\n",
    "[ ] Validate JSON structure from LLM\n",
    "[ ] Verify entity positions are within text bounds\n",
    "[ ] Check extracted text matches source at positions\n",
    "[ ] Validate entity format (SSN format, routing number checksum)\n",
    "\n",
    "PII HANDLING (CRITICAL FOR BANKING)\n",
    "[ ] Flag PII entities immediately\n",
    "[ ] Mask PII before logging\n",
    "[ ] Separate storage for PII vs non-PII entities\n",
    "[ ] Audit trail for PII access\n",
    "\n",
    "ACCURACY MONITORING\n",
    "[ ] Sample predictions for human review\n",
    "[ ] Track entity-type-specific precision/recall\n",
    "[ ] Alert on confidence score drops\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Traditional vs LLM Comparison\n",
    "\n",
    "| Dimension | Traditional (CRF) | BERT-NER | GLiNER | LLM (GPT-4) |\n",
    "|-----------|------------------|----------|--------|-------------|\n",
    "| **Entity F1** | 85-90% | 92-95% | 80-88% | 75-90% |\n",
    "| **Custom entities** | Retrain | Retrain | Zero-shot | Zero-shot |\n",
    "| **Nested entities** | Hard | Hard | Natural | Natural |\n",
    "| **Latency** | <20ms | 50-100ms | 100-200ms | 500ms-2s |\n",
    "| **Cost/doc** | ~$0 | $0.0001 | $0.001 | $0.01-0.02 |\n",
    "| **Explainability** | High | Low | Medium | Medium |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Techniques\n",
    "\n",
    "### Nested Entity Extraction\n",
    "```python\n",
    "# LLMs naturally handle:\n",
    "# \"Bank of America headquarters\" -> ORG: \"Bank of America\", LOC: \"Bank of America headquarters\"\n",
    "```\n",
    "\n",
    "### Entity Linking\n",
    "```python\n",
    "# After extraction, link to knowledge base:\n",
    "# \"Chase\" -> Chase Bank NA (OCC Charter #24)\n",
    "# \"BoA\" -> Bank of America Corporation (NYSE: BAC)\n",
    "```\n",
    "\n",
    "### Relation Extraction\n",
    "```python\n",
    "prompt = \"\"\"Extract entities AND their relationships:\n",
    "Text: \"John Smith transferred $5000 to Mary Johnson\"\n",
    "Entities: John Smith (PERSON), $5000 (MONEY), Mary Johnson (PERSON)\n",
    "Relations: John Smith --[transferred]--> $5000 --[to]--> Mary Johnson\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interview Soundbites\n",
    "\n",
    "**On GLiNER:**\n",
    "> \"GLiNER is a game-changer for banking NER. Instead of training a model for every new entity type, I just add 'ROUTING_NUMBER' to the label list. It understands what a routing number is from pre-training.\"\n",
    "\n",
    "**On BERT vs LLM:**\n",
    "> \"For high-volume NER with fixed entity types, fine-tuned BERT wins. For document processing where entity types vary by document, LLM prompting is more flexible. I use BERT for transaction monitoring (millions/day) and LLM for contract analysis (hundreds/day).\"\n",
    "\n",
    "**On PII Detection:**\n",
    "> \"For PII, I run multiple extractors in parallel - regex patterns for known formats (SSN, account numbers) plus LLM for fuzzy matches ('my social is one two three...'). The union ensures high recall, and we can tolerate some false positives for compliance.\"\n",
    "\n",
    "**On Validation:**\n",
    "> \"Never trust LLM NER output without validation. I always verify: (1) the extracted text exists at the claimed position, (2) the format matches the entity type, (3) the entity makes sense in context. LLMs can hallucinate entities.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Q: How do you handle entity types the model hasn't seen?**\n",
    "> GLiNER or LLM prompting for zero-shot. If accuracy isn't good enough, collect 50-100 examples and fine-tune. For banking-specific entities like SWIFT codes, I often combine regex patterns with LLM for fuzzy cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║                    NOTEBOOK SUMMARY                               ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║  Task: Named Entity Recognition with LLMs                        ║\n",
    "║  Approaches: BERT-NER, GLiNER, LLM Prompting                     ║\n",
    "║  Banking Use: PII detection, document extraction                 ║\n",
    "║                                                                  ║\n",
    "║  Key Takeaways:                                                  ║\n",
    "║  1. GLiNER enables zero-shot custom entity extraction            ║\n",
    "║  2. LLMs handle nested entities naturally                        ║\n",
    "║  3. Always validate LLM output (positions, format)               ║\n",
    "║  4. BERT-NER for high volume, LLM for flexibility                ║\n",
    "║  5. Combine regex + LLM for PII (high recall)                    ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
